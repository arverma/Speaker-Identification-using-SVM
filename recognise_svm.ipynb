{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read\n",
    "from speakerfeatures import get_MFCC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source   = \"development_set\\\\\"\n",
    "dest = \"speaker_models\\\\\"\n",
    "train_file = \"development_set_enroll_5.txt\" # \"train.txt\" # \n",
    "n_files = 5 #training_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Modeled : akshay_hindi , Training Data: 19.969160997732427 , MFCC: 40\n",
      "\n",
      "2 Modeled : aman_maghi , Training Data: 8.4649375 , MFCC: 40\n",
      "\n",
      "3 Modeled : aman_realtime , Training Data: 19.969160997732427 , MFCC: 40\n",
      "\n",
      "4 Modeled : aman , Training Data: 28.16458049886621 , MFCC: 40\n",
      "\n",
      "5 Modeled : ankit_maithli , Training Data: 19.969160997732427 , MFCC: 40\n",
      "\n",
      "6 Modeled : premananda_manipur , Training Data: 19.969160997732427 , MFCC: 40\n",
      "\n",
      "7 Modeled : sumit_up , Training Data: 19.969160997732427 , MFCC: 40\n",
      "\n",
      "8 Modeled : anthonyschaller , Training Data: 16.0 , MFCC: 40\n",
      "\n",
      "9 Modeled : Apple_Eater , Training Data: 20.8213125 , MFCC: 40\n",
      "\n",
      "10 Modeled : Ara , Training Data: 40.5 , MFCC: 40\n",
      "\n",
      "11 Modeled : argail , Training Data: 24.75 , MFCC: 40\n",
      "\n",
      "12 Modeled : ariyan , Training Data: 25.125 , MFCC: 40\n",
      "\n",
      "13 Modeled : arjuan , Training Data: 27.125 , MFCC: 40\n",
      "\n",
      "14 Modeled : armond , Training Data: 53.37225 , MFCC: 40\n",
      "\n",
      "15 Modeled : Artem , Training Data: 28.0 , MFCC: 40\n",
      "\n",
      "16 Modeled : arthur , Training Data: 37.875 , MFCC: 40\n",
      "\n",
      "17 Modeled : artk , Training Data: 33.75 , MFCC: 40\n",
      "\n",
      "18 Modeled : arun , Training Data: 30.375 , MFCC: 40\n",
      "\n",
      "19 Modeled : arvala , Training Data: 27.25 , MFCC: 40\n",
      "\n",
      "20 Modeled : asalkeld , Training Data: 33.0 , MFCC: 40\n",
      "\n",
      "21 Modeled : asladic , Training Data: 23.1770625 , MFCC: 40\n",
      "\n",
      "22 Modeled : AslakKnutsen , Training Data: 26.75 , MFCC: 40\n",
      "\n",
      "23 Modeled : asp , Training Data: 25.125 , MFCC: 40\n",
      "\n",
      "24 Modeled : AT , Training Data: 27.0 , MFCC: 40\n",
      "\n",
      "25 Modeled : atamur , Training Data: 20.625 , MFCC: 40\n",
      "\n",
      "26 Modeled : ataru80 , Training Data: 28.375 , MFCC: 40\n",
      "\n",
      "27 Modeled : atterer , Training Data: 20.24675 , MFCC: 40\n",
      "\n",
      "28 Modeled : audioodyssey , Training Data: 32.25 , MFCC: 40\n",
      "\n",
      "29 Modeled : avsa242 , Training Data: 27.136125 , MFCC: 40\n",
      "\n",
      "30 Modeled : ax , Training Data: 27.25 , MFCC: 40\n",
      "\n",
      "31 Modeled : axllaruse , Training Data: 33.875 , MFCC: 40\n",
      "\n",
      "32 Modeled : azmisov , Training Data: 22.5 , MFCC: 40\n",
      "\n",
      "33 Modeled : B , Training Data: 26.3679375 , MFCC: 40\n",
      "\n",
      "34 Modeled : bachroxx , Training Data: 19.625 , MFCC: 40\n",
      "\n",
      "35 Modeled : bae , Training Data: 27.25 , MFCC: 40\n",
      "\n",
      "36 Modeled : Bahoke , Training Data: 18.125 , MFCC: 40\n",
      "\n",
      "37 Modeled : Bareford , Training Data: 28.5 , MFCC: 40\n",
      "\n",
      "38 Modeled : bart , Training Data: 20.847625 , MFCC: 40\n",
      "\n",
      "39 Modeled : Bassel , Training Data: 28.375 , MFCC: 40\n",
      "\n",
      "40 Modeled : bdutta , Training Data: 18.875 , MFCC: 40\n",
      "\n",
      "41 Modeled : beady , Training Data: 24.1494375 , MFCC: 40\n",
      "\n",
      "42 Modeled : bebe , Training Data: 24.875 , MFCC: 40\n",
      "\n",
      "43 Modeled : becz03 , Training Data: 25.0 , MFCC: 40\n",
      "\n",
      "44 Modeled : beez1717 , Training Data: 21.375 , MFCC: 40\n",
      "\n",
      "45 Modeled : belmontguy , Training Data: 26.0 , MFCC: 40\n",
      "\n",
      "46 Modeled : ben , Training Data: 20.3948125 , MFCC: 40\n",
      "\n",
      "47 Modeled : bencoder , Training Data: 25.77075 , MFCC: 40\n",
      "\n",
      "48 Modeled : bendauphinee , Training Data: 25.125 , MFCC: 40\n",
      "\n",
      "49 Modeled : bendra , Training Data: 28.625 , MFCC: 40\n",
      "\n",
      "50 Modeled : bennmann , Training Data: 23.125 , MFCC: 40\n",
      "\n",
      "51 Modeled : benob , Training Data: 23.3814375 , MFCC: 40\n",
      "\n",
      "52 Modeled : benoliver999 , Training Data: 31.75 , MFCC: 40\n",
      "\n",
      "53 Modeled : Berrym , Training Data: 30.375 , MFCC: 40\n",
      "\n",
      "54 Modeled : BFG , Training Data: 26.125 , MFCC: 40\n",
      "\n",
      "55 Modeled : bhart , Training Data: 24.25 , MFCC: 40\n",
      "\n",
      "56 Modeled : bhavanikrishna , Training Data: 30.5 , MFCC: 40\n",
      "\n",
      "57 Modeled : BhushanNKIITBombay , Training Data: 40.375 , MFCC: 40\n",
      "\n",
      "58 Modeled : bhuvan , Training Data: 32.6826875 , MFCC: 40\n",
      "\n",
      "59 Modeled : bigmbywater , Training Data: 20.5 , MFCC: 40\n",
      "\n",
      "60 Modeled : BigMick , Training Data: 19.712125 , MFCC: 40\n",
      "\n",
      "61 Modeled : BillMorgan , Training Data: 34.125 , MFCC: 40\n",
      "\n",
      "62 Modeled : Bitbrit , Training Data: 14.75 , MFCC: 40\n",
      "\n",
      "63 Modeled : Blackdrive , Training Data: 25.00275 , MFCC: 40\n",
      "\n",
      "64 Modeled : Blenderkitty , Training Data: 20.625 , MFCC: 40\n",
      "\n",
      "65 Modeled : BlindPilot , Training Data: 25.5 , MFCC: 40\n",
      "\n",
      "66 Modeled : blood , Training Data: 26.125 , MFCC: 40\n",
      "\n",
      "67 Modeled : bloomtom , Training Data: 25.0028125 , MFCC: 40\n",
      "\n",
      "68 Modeled : BlueAgent , Training Data: 23.75 , MFCC: 40\n",
      "\n",
      "69 Modeled : BlueB , Training Data: 13.3120625 , MFCC: 40\n",
      "\n",
      "70 Modeled : bluefox83 , Training Data: 29.27 , MFCC: 40\n",
      "\n",
      "71 Modeled : bluepeppers , Training Data: 26.125 , MFCC: 40\n",
      "\n",
      "72 Modeled : bluSch , Training Data: 22.0173125 , MFCC: 40\n",
      "\n",
      "73 Modeled : Bob , Training Data: 22.625 , MFCC: 40\n",
      "\n",
      "74 Modeled : BobHallstrom , Training Data: 44.5 , MFCC: 40\n",
      "\n",
      "75 Modeled : bobriva123 , Training Data: 39.79375 , MFCC: 40\n",
      "Avg training_data: 29.041700833333334\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "file_paths = open(train_file,'r')\n",
    "\n",
    "label_dict = {}\n",
    "y_train = []\n",
    "x_train = np.asarray(())\n",
    "features = np.asarray(())\n",
    "avg_data = 0\n",
    "training_data = 0\n",
    "\n",
    "for i, path in enumerate(file_paths):    \n",
    "    path = path.strip()   \n",
    "    #print(path)\n",
    "    Fs, audio = read(source + path)\n",
    "    vector = get_MFCC(audio, Fs, 20)\n",
    "    training_data += len(audio)\n",
    "    \n",
    "    if features.size == 0:\n",
    "        features = vector\n",
    "    else:\n",
    "        features = np.vstack((features, vector))\n",
    "    #print(len(features))\n",
    "    # when features of 5 files of speaker are concatenated, then do model training\n",
    "    if count == n_files:    \n",
    "        if x_train.size == 0:\n",
    "            x_train = features\n",
    "        else:\n",
    "            x_train = np.vstack((x_train, features))\n",
    "        for j in range(len(features)):\n",
    "            y_train.append((i+1)//n_files)\n",
    "        print()\n",
    "        mn = features.shape\n",
    "        print((i+1)//n_files, 'Modeled :',path.split(\"-\")[0], \", Training Data:\", training_data/Fs, \", MFCC:\", mn[1])\n",
    "        label_dict[(i+1)//n_files] = path.split(\"-\")[0]\n",
    "        features = np.asarray(())\n",
    "        avg_data += training_data\n",
    "        training_data = 0\n",
    "        count = 0\n",
    "    count = count + 1\n",
    "file_paths.close()\n",
    "print(\"Avg training_data:\", avg_data/(Fs*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training_data: 29.041700833333334\n"
     ]
    }
   ],
   "source": [
    "print(\"Avg training_data:\", avg_data/(Fs*75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'akshay_hindi',\n",
       " 2: 'aman_maghi',\n",
       " 3: 'aman_realtime',\n",
       " 4: 'aman',\n",
       " 5: 'ankit_maithli',\n",
       " 6: 'premananda_manipur',\n",
       " 7: 'sumit_up',\n",
       " 8: 'anthonyschaller',\n",
       " 9: 'Apple_Eater',\n",
       " 10: 'Ara',\n",
       " 11: 'argail',\n",
       " 12: 'ariyan',\n",
       " 13: 'arjuan',\n",
       " 14: 'armond',\n",
       " 15: 'Artem',\n",
       " 16: 'arthur',\n",
       " 17: 'artk',\n",
       " 18: 'arun',\n",
       " 19: 'arvala',\n",
       " 20: 'asalkeld',\n",
       " 21: 'asladic',\n",
       " 22: 'AslakKnutsen',\n",
       " 23: 'asp',\n",
       " 24: 'AT',\n",
       " 25: 'atamur',\n",
       " 26: 'ataru80',\n",
       " 27: 'atterer',\n",
       " 28: 'audioodyssey',\n",
       " 29: 'avsa242',\n",
       " 30: 'ax',\n",
       " 31: 'axllaruse',\n",
       " 32: 'azmisov',\n",
       " 33: 'B',\n",
       " 34: 'bachroxx',\n",
       " 35: 'bae',\n",
       " 36: 'Bahoke',\n",
       " 37: 'Bareford',\n",
       " 38: 'bart',\n",
       " 39: 'Bassel',\n",
       " 40: 'bdutta',\n",
       " 41: 'beady',\n",
       " 42: 'bebe',\n",
       " 43: 'becz03',\n",
       " 44: 'beez1717',\n",
       " 45: 'belmontguy',\n",
       " 46: 'ben',\n",
       " 47: 'bencoder',\n",
       " 48: 'bendauphinee',\n",
       " 49: 'bendra',\n",
       " 50: 'bennmann',\n",
       " 51: 'benob',\n",
       " 52: 'benoliver999',\n",
       " 53: 'Berrym',\n",
       " 54: 'BFG',\n",
       " 55: 'bhart',\n",
       " 56: 'bhavanikrishna',\n",
       " 57: 'BhushanNKIITBombay',\n",
       " 58: 'bhuvan',\n",
       " 59: 'bigmbywater',\n",
       " 60: 'BigMick',\n",
       " 61: 'BillMorgan',\n",
       " 62: 'Bitbrit',\n",
       " 63: 'Blackdrive',\n",
       " 64: 'Blenderkitty',\n",
       " 65: 'BlindPilot',\n",
       " 66: 'blood',\n",
       " 67: 'bloomtom',\n",
       " 68: 'BlueAgent',\n",
       " 69: 'BlueB',\n",
       " 70: 'bluefox83',\n",
       " 71: 'bluepeppers',\n",
       " 72: 'bluSch',\n",
       " 73: 'Bob',\n",
       " 74: 'BobHallstrom',\n",
       " 75: 'bobriva123'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311446, 40, 1, 'akshay_hindi')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_train[0]), y_train[0], label_dict[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(311446, 311446)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(C=1, class_weight = \"balanced\", decision_function_shape = 'ovo')\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picklefile = \"model_5_rbf.svm\"\n",
    "cPickle.dump(model, open(dest + picklefile,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"development_set_test.txt\"  # \"test.txt\" #   \n",
    "file_paths = open(test_file, 'r')\n",
    "\n",
    "svm_model = cPickle.load(open(dest + \"model_5_rbf.svm\",'rb'))\n",
    "\n",
    "files  = [os.path.join(source, f[0:len(f)-1]) for f in file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[0].split(\"\\\\\")[1].split(\"-\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "total_sample = 0\n",
    "for i, path in enumerate(files):\n",
    "    total_sample += 1\n",
    "    Fs, audio = read(path)\n",
    "    vector = get_MFCC(audio, Fs, 20)\n",
    "    temp = svm_model.predict(vector)\n",
    "    y_test = Counter(temp).most_common()[0]\n",
    "    if(path.split(\"\\\\\")[1].split(\"-\")[0] == label_dict[y_test[0]]):\n",
    "        accuracy += 1\n",
    "        print(i+1, \":\", path.split(\"\\\\\")[1].split(\"-\")[0], \"Predicted as:\", label_dict[y_test[0]])\n",
    "    else:\n",
    "        print(\"-----------------------------------------------\")\n",
    "        print(i+1, \":\", path.split(\"\\\\\")[1].split(\"-\")[0], \"Predicted as:\", label_dict[y_test[0]])\n",
    "        print(\"-----------------------------------------------\")\n",
    "print(\"Accuracy =\", accuracy/total_sample*100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 99.75124378109453 %, C=1, class_weight = \"balanced\", MFCC = 20, training data = 3 files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 95.86776859504133 %, C=1, class_weight = \"balanced\", MFCC = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 95.86776859504133 %, C=1, class_weight = \"balanced\", decision_function_shape = 'ovo', MFCC = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy = 100.0 %SVC(C=1, class_weight = \"balanced\", decision_function_shape = 'ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs, audio = read(\"development_set\\\\Apple_Eater-20091026-yul\\\\wav\\\\a0061.wav\")\n",
    "vector = get_MFCC(audio, Fs, 20)\n",
    "temp = svm_model.predict(vector)\n",
    "plt.plot(temp)\n",
    "from collections import Counter m\n",
    "y_test = Counter(temp).most_common()[0]\n",
    "print(\"Predicted as:\", label_dict[y_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(temp).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "204/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
